---
title: "Nonlinear Models"
output: html_document
---

```{r}
require(ISLR)
attach(Wage)
```

Polynomials
---

Focus on single predictor age:

```{r}
fit=lm(wage~poly(age,4),data=Wage)
summary(fit)
```

function `poly` creates *orthogonal polynomials*

make plot with fitted function and standard errors of fit

```{r fig.width=7, fig.height=6}
agelims=range(age)
age.grid=seq(from=agelims[1],to=agelims[2])
age.grid
preds=predict(fit,newdata=list(age=age.grid),se=TRUE)
se.bands=cbind(preds$fit+2*preds$se, preds$fit-2*preds$se)
se.bands[1:5,]
plot(age,wage,col="darkgrey")
lines(age.grid,preds$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,col="blue",lty=2)
```

more direct ways of doing this

```{r}
fita=lm(wage~age+I(age^2)+I(age^3)+I(age^4),data=Wage)
summary(fita)
```

`I()` is a *wrapper* function; needed b/c `age^2` means something to formula language, while `I(age^2)` is protected.

different coefficients but the same fit:

```{r}
plot(fitted(fit), fitted(fita))
```

"By using orhtogonal polynomials in this simple way, it turns out that we can separately test for each coefficient. So if we look at the summary again, we can see that the linear, quadratic, and cubic terms are significant, but not the quartic."

```{r}
summary(fit)
```

"This only works with linear regression, and if there is a single predictor. In general we would use `anova()`..."

```{r}
fita=lm(wage~education,data=Wage)
fitb=lm(wage~education+age,data=Wage)
fitc=lm(wage~education+poly(age,2),data=Wage)
fitd=lm(wage~education+poly(age,3),data=Wage)
anova(fita,fitb,fitc,fitd)
```

### Polynomial logistic regression

binary response variable; code the big earners (`>250k`) as 1, else 0

```{r}
fit=glm(I(wage>250) ~ poly(age,3), data=Wage, family=binomial)
summary(fit)
preds=predict(fit,list(age=age.grid),se=T)
se.bands=preds$fit + cbind(fit=0,lower=-2*preds$se,upper=2*preds$se)
se.bands[1:5,]
```

computations on logit scale; to transform we need to apply inverse logit mapping
$$p=\frac{e^\eta}{1+e^\eta}.$$
[above is Markdown interpretation of TeX expression]

apply transformation simultaneously to all three `se.bands` columns:

```{r}
prob.bands=exp(se.bands)/(1+exp(se.bands))
prob.bands[1:5,]
matplot(age.grid,prob.bands,col="blue",lwd=c(2,1,1),lty=c(1,2,2),type="l",ylim=c(0,.1))
points(jitter(age),I(wage>250)/10,pch="|",cex=.5)
```

Splines
---

* more flexible than polynomials
* more local than polynomails
function `bs` specifies the basis

```{r}
require(splines)
fit=lm(wage~bs(age,knots=c(25,40,60)),data=Wage)
plot(age,wage,col="darkgray")
lines(age.grid,predict(fit,list(age=age.grid)),col="darkgreen",lwd=2)
abline(v=c(25,40,60),lty=2,col="darkgreen")


#smoothing splines do not require knot selection but does have a smoothing parameter which can be selected via effective degrees of freedom, `df`

fit=smooth.spline(age,wage,df=16)
lines(fit,col="red",lwd=2)


# we use leave-one-out (LOO) cross-validation to select smoothing parameter:

fit=smooth.spline(age,wage,cv=TRUE)
lines(fit,col="purple",lwd=2)
fit
```


Generalized Additive Models
---

`gam` package makes it easy to work with multiple nonlinear terms

```{r fig.width=10, fig.height=5}
require(gam)
gam1=gam(wage~s(age,df=4)+s(year,df=4)+education,data=Wage)
par(mfrow=c(1,3))
plot(gam1,se=T)

gam2=gam(I(wage>250)~s(age,df=4)+s(year,df=4)+education,data=Wage,family=binomial)
# leave out standard errors (se) because very wide
plot(gam2)
```

explore need for nonlinear terms for year

```{r}
gam2a=gam(I(wage>250)~s(age,df=4)+year+education,data=Wage,family=binomial)
anova(gam2a,gam2,test="Chisq")
```

`gam` package able to plot functions nicely, even for models fit by `lm` and `glm`

```{r fig.width=10, fig.height=5}
par(mfrow=c(1,3))
# natural spines, "ns"
lm1=lm(wage~ns(age,df=4)+ns(year,df=4)+education,data=Wage)
plot.gam(lm1,se=T)
